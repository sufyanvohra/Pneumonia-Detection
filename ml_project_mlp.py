# -*- coding: utf-8 -*-
"""ML_project_MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ismr8aG-PCMj44yhXeUlCD6feMieZKv7
"""



import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
from pathlib import Path
import pandas as pd
import seaborn as sns
import cv2
from skimage.util import img_as_float
from sklearn.utils import shuffle
from functools import partial
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D, GlobalMaxPooling2D
from keras.layers.normalization import BatchNormalization
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

drive.mount('/content/drive')

data_dir_train = Path("/content/drive/MyDrive/train")
data_dir_test = Path("/content/drive/MyDrive/test")

def image_processing(data_dir):
  normal_dir = data_dir / "NORMAL"
  pneumonia_dir = data_dir / "PNEUMONIA"

  processed_data = []
  train_labels = []

  for img in normal_dir.glob('*.jpeg'):
      
      img = cv2.imread(str(img))
      img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
      img = cv2.resize(img, (224,224))
      img = img.flatten().reshape(50176,)
      img = img_as_float(np.array(img))
      train_labels.append(0)
      processed_data.append((img))

  for img in pneumonia_dir.glob('*.jpeg'):
      
      img = cv2.imread(str(img))
      img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
      img = cv2.resize(img, (224,224))
      img = img.flatten().reshape(50176,)
      img = img_as_float(np.array(img))
      train_labels.append(1)
      processed_data.append((img))

  processed_data, train_labels =shuffle(processed_data,train_labels) 
  return processed_data, train_labels

processed_data_train,train_labels = image_processing(data_dir_train)
processed_data_test,test_labels = image_processing(data_dir_test)


processed_data_train = np.array(processed_data_train)
train_labels = np.array(train_labels)

processed_data_test = np.array(processed_data_test)
test_labels = np.array(test_labels)

model = Sequential()
model.add(Dense(1024, activation='relu', input_shape=(50176,)))
model.add(Dense(1024, activation='relu'))
model.add(Dense(1024, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(processed_data_train[:4400],train_labels[:4400], batch_size=32, epochs=10, verbose=1,validation_data=(processed_data_train[4400:],train_labels[4400:]))

[test_loss, test_acc] = model.evaluate(processed_data_test, test_labels)
print("Evaluation result on Test Data : Loss = {}, accuracy = {}".format(test_loss, test_acc))
print("")
predictions = predictions = (model.predict(processed_data_test) > 0.5).astype("int32")
print(classification_report(test_labels, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))
print("Confusion Matrix: ")
print(confusion_matrix(test_labels, predictions))

#Plot the Loss Curves
plt.figure(figsize=[8,6])
plt.plot(history.history['loss'],'b',linewidth=3.0)
plt.plot(history.history['val_loss'],'g',linewidth=3.0)
plt.legend(['Training loss', 'Validation Loss'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Loss',fontsize=16)
plt.title('Loss Curves',fontsize=16)
#Plot the Accuracy Curves
plt.figure(figsize=[8,6]) 
plt.plot(history.history['accuracy'],'r',linewidth=3.0)
plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)
plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Accuracy',fontsize=16)
plt.title('Accuracy Curves',fontsize=16)

import numpy as np
fi = []
fi.append([1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3])
fi.append([1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3,1,2,3,3])
fi.append([1,2,3,3])
fi.append( [4,5,6,5])
print(fi)
fi = np.array(fi)
print(fi.shape)

